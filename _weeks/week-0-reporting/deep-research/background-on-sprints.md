# Sprint-Week Models: Google Ventures Design Sprint vs. Design Thinking Double Diamond

**Introduction**
In product innovation and design, **“sprint-week” frameworks** have emerged as powerful tools to quickly solve problems and test ideas. Two foundational models stand out: (1) the **Google Ventures (GV) five-day Design Sprint**, and (2) the **Design Thinking sprint mapped to the Double Diamond process**. This essay provides a deep historical and conceptual overview of both models, tracing their origins, outlining their structures and phases, and examining their goals, methods, and philosophies. It also compares and contrasts the two approaches, and reflects on how they might be adapted when **multiple teams work in parallel under a shared theme**. Throughout, we draw on authoritative sources – including GV’s own documentation, *Sprint* (the book by Jake Knapp et al.), and foundational design thinking texts from IDEO, Stanford d.school, and the UK Design Council – to understand how these sprint models were born and how they function in practice.

## Origins of the Google Ventures Five-Day Design Sprint

The **GV Design Sprint** was created within Google’s culture of rapid innovation. **Jake Knapp**, then a designer at Google, ran the very first design sprint in 2010 on the Gmail team. Knapp’s idea was to compress what could be months of work into an intensive one-week exercise. He drew inspiration from several sources – Google’s fast-paced product development culture, as well as design thinking practices at IDEO and Stanford’s d.school. The early success of sprints at Google (with teams like Chrome, Search, and Google X) led Knapp to bring the process to Google Ventures (GV) in 2012. At GV, a team of design partners refined and formalized the method. Key figures including **Braden Kowitz**, **Michael Margolis**, **John Zeratsky**, and **Daniel Burka** contributed their expertise: Kowitz introduced a *“story-centered design”* focus on user journeys; Margolis streamlined user research into a one-day test; Zeratsky emphasized defining success metrics from the start; and Burka ensured each step made practical sense for startups. These contributions shaped the sprint into a repeatable formula. By mid-decade, the process had been battle-tested with numerous GV portfolio companies, and in 2016 Knapp, Zeratsky, and Kowitz published *Sprint*, a book detailing the method for a wider audience. The GV sprint quickly gained prominence as a go-to framework for startups and innovation teams, promising a fast track from idea to tested prototype.

**Early Implementations:** Some of the first high-profile implementations were within GV’s own investments. For example, GV ran sprints with companies like Nest, Flatiron Health, Medium, Slack, Blue Bottle Coffee, and others to help tackle various challenges – entering new markets, designing new product features, refining user experiences, or even defining marketing strategies. These early cases demonstrated that the sprint could *“scale well regardless of team size or company”*. Even tech media took note: in 2013, *TechCrunch* described how GV’s **“all-star team of designers”** used sprints as an *“intensive, visual bootcamp”* for startups, condensing processes that might normally take six months into five days. By focusing a small cross-functional team on a specific problem and clearing their schedules for a week, GV showed that a sprint can produce tangible results – a tested prototype and customer feedback – with extraordinary speed. This heritage underlines the sprint’s origin as a tool born in the startup world, where time and resources are limited and rapid validation is crucial.

## Structure and Phases of the GV Design Sprint

The **GV Design Sprint is a structured five-day process** with distinct phases each day. As GV defines it, *“The sprint is a five-day process for answering critical business questions through design, prototyping, and testing ideas with customers.”* It’s essentially a *“greatest hits”* compilation of strategies from business, innovation, **behavioral science**, and **design thinking**, distilled into a *“battle-tested process that any team can use.”* The core idea is to give teams a **shortcut to learning** – compressing the usual cycle of debating, building, and launching into a one-week experiment. Below is a breakdown of the sprint’s structure, phases, and key activities:

* **Monday – Map and Define:** The sprint week begins by **unpacking the problem space**. The team (typically 5–7 people from diverse functions, plus a facilitator) first shares background knowledge and user insights. They might conduct brief expert interviews (with stakeholders or subject-matter experts) and capture challenges as “How Might We” notes. By midday, the team defines a **long-term goal** for the project and lists the tough questions that need to be answered (often called sprint questions). In the afternoon, they create a simple map of the user’s journey or flow. Finally, through structured discussion and voting, they **choose a target**: a specific point on the map, or a specific sub-problem, that is both important and feasible to tackle in one week. This decision on Monday – picking an ambitious but focused challenge – sets the course for the sprint.

* **Tuesday – Sketch Solutions:** With a clear target in mind, Tuesday is devoted to **exploring solutions**. The day kicks off with **inspiration** (“Lightning Demos”), where team members review existing ideas or competitor products for inspiration and *“to remix and improve”* upon. Then each person works individually to sketch potential solutions on paper. Notably, the sprint uses a **four-step sketch process** to guide people from rough ideas to a detailed solution sketch. This includes steps like making notes, doodling rough concepts, doing *Crazy 8’s* (eight quick sketches in 8 minutes to push beyond the obvious), and finally drawing a refined **solution sketch**. The emphasis is on **critical thinking over artistry** – meaning anyone can sketch as long as the idea is clear. By day’s end, the team has a stack of diverse solution sketches. Additionally, on Tuesday the team will start recruiting users for Friday’s test – identifying a target profile and scheduling five customers to participate (five users is a typical number in design sprint testing, following best practices from usability research).

* **Wednesday – Decide and Storyboard:** By Wednesday morning, a *“stack of solutions”* is on the table. The challenge now is **deciding which idea to prototype**, since attempting to prototype everything is impractical. The day begins with each solution being **critiqued**. The team might use a structured review: each sketch is posted (anonymously) in a makeshift gallery (often called an “art museum” display), and the team walks around to discuss pros and cons. They use dot stickers to vote on the most promising parts of each solution (“heat map” voting). With all ideas considered, the **Decider** (usually a team leader or product owner designated to have final say) makes the call on which concept (or combination of ideas) will be pursued. This critical decision aligns everyone on a single direction. Next, the team moves into storyboarding. They take the winning idea and **create a storyboard**, a step-by-step outline of the user experience – typically an 8–15 frame sketch of screens or moments that need to happen in the prototype. This storyboard is essentially the blueprint for the prototype to be built. By the end of Wednesday, the team has a clear plan: which solution they’ll prototype and exactly what flow or scenes the prototype will cover.

* **Thursday – Prototype:** On Thursday, the motto is **“fake it to make it.”** The team spends the day **building a realistic prototype** of the chosen solution, but they do so with a “Goldilocks” approach – just real enough to get credible feedback, but built as fast as possible. As the GV guide explains, *“you’ll adopt a ‘fake it’ philosophy to turn the storyboard into a prototype. A realistic façade is all you need… by focusing on the customer-facing surface of your product or service, you can finish your prototype in just one day.”* In practice, this often means dividing tasks among the team: some might focus on visual design (perhaps using PowerPoint/Keynote, simple HTML, or a design tool to mock up screens), others on interaction (linking screens in a clickable prototype), and others prepping any physical props or data needed. The prototype is typically high-fidelity in appearance but “Wizard of Oz” behind the scenes – for example, a fake landing page or a semi-functional app simulation. The goal is to **simulate the intended user experience** closely enough that users in a test behave realistically. Throughout Thursday, the team also prepares for the next day’s test: confirming the schedule with recruited users, and writing an interview script or questionnaire. By end of day, they do a trial run of the prototype to ensure everything is ready.

* **Friday – Test and Learn:** Friday is all about **user testing**. The team invites in their five target users, one at a time, and conducts **customer interviews** while observing how the users interact with the prototype. GV’s process emphasizes a structured interview format – the **five-act interview** – to get *“crystal clear results in just one day”*. A typical setup is that one team member (often a researcher or the sprint facilitator) interviews the user in a room with the prototype, while the rest of the team watches via video in another room and takes notes. By the end of the day, the team has collected rich feedback: what delighted users, what confused them, and whether the idea seems to solve the intended problem. **This test makes the entire sprint worthwhile** – it effectively *fast-forwards into the future* to show the outcome of the idea without the cost of a full build. The week concludes with the team synthesizing the findings and deciding on next steps. Often, the results will indicate whether the idea should move forward (with perhaps some tweaks), or whether major changes (or even a pivot) are needed. In either case, the sprint has drastically reduced the risk by learning in days what might have taken months.

Overall, the GV sprint’s structure is laser-focused on **speed-to-learning and team alignment**. Each phase has a clear goal and deliverable: a defined target, a set of sketches, a decided concept storyboard, a prototype, and validated user feedback. The process intentionally breaks the usual silos and “endless debate cycle” of product development. By enforcing tight time boxes (the team literally uses a timer for exercises) and a step-by-step checklist, the sprint forces decisions and creates momentum. Yet it’s not just about speed; as Knapp notes, it’s also about a *“more effective way of solving problems that brings out the best contributions of everyone on the team”*, rather than defaulting to hierarchy or endless meetings. In sum, the GV Design Sprint provides a **time-constrained, user-centered experiment**: in one week, a team moves from a problem to a tested solution, grounded in real user insight.

## Tools and Methods Used in the GV Sprint

Each phase of the GV sprint comes with a **toolkit of methods** to facilitate teamwork and creativity. On **Monday**, for example, teams often use **user journey mapping** to visualize the problem, and **“How Might We” (HMW) notes** to reframe pain points as opportunities. They also employ techniques for setting direction, such as writing a **Long-Term Goal** (a guiding star for what they want to achieve if the solution succeeds) and enumerating **Sprint Questions** (riskiest uncertainties they need to answer during the week). On **Tuesday**, the **Lightning Demos** method is used to survey existing solutions for inspiration; then the **Four-Step Sketch** process structures individual ideation (steps: Notes → Ideas → *Crazy 8’s* → Solution Sketch). The *Crazy 8’s* exercise in particular is a classic design sprint activity that pushes team members to generate eight quick variations of an idea in 8 minutes – a timed creativity challenge to yield innovative ideas.

On **Wednesday**, decision-making tools come into play. The team might use **dot voting** to identify promising elements in the sketches (each team member dot-votes on parts of sketches they like, creating a “heat map” of popular ideas). They often do a **speed critique** or structured review of each sketch, ensuring every concept is understood. A designated **Decider** (often an executive or product owner in the sprint) then uses insights from the team to make the final call – sometimes using special “super-votes” to mark their choice. Once a concept is chosen, the team storyboards it using a whiteboard or large paper, drawing a comic-strip-like sequence. This storyboard stage is heavily influenced by what Braden Kowitz termed *“story-centered design,”* focusing the solution on a coherent user story from start to finish. The storyboard doubles as a project plan for prototyping.

On **Thursday (Prototype day)**, teams employ **rapid prototyping tools**. Common approaches include using design software (like Figma, Sketch, or even PPT/Keynote for clickable mocks), and adopting a *“fake it”* mentality – for instance, using dummy data or manually simulating backend responses. The idea is to build the *“Goldilocks quality”* prototype: just polished enough to appear real to a user, but no more. Collaboration is key; teams often split into roles – e.g., one person crafts visuals, another wires up interactions, another writes any content or copy, another acts as the “stitcher” to pull it all together. A **trial run** of the prototype is done to catch issues. Simultaneously, **preparing for testing** means writing an interview script. GV’s Michael Margolis developed the **Five-Act Interview** method to structure the user test: it includes a friendly introduction, a series of tasks or scenarios for the user to perform with the prototype, open-ended feedback questions, etc., all designed to put the user at ease and gather unbiased feedback.

On **Friday**, the primary “tool” is the **user interview** itself. A researcher or facilitator conducts one-on-one interviews, often following the five-act script (Act 1: introductions, Act 2: context questions, Act 3: introduce the prototype tasks, Act 4: detailed task scenarios, Act 5: debrief and ask for overall impressions). The rest of the team observes silently (often via video feed in another room or via Zoom for remote sprints) and takes notes using a template to capture observations. After each interview, the team does a quick debrief to list key insights, and by the end of the day they synthesize patterns across the five interviews – typically categorizing what aspects of the prototype worked, what didn’t, and gleaning any **design or product strategy implications**. This immediate synthesis allows the team to decide on the Monday after the sprint how to proceed (iterate the prototype, implement it, or pivot away). The sprint week thus ends not only with a prototype, but with **data-driven recommendations** for next steps.

**Underlying Philosophy of the GV Sprint:** Several core principles drive the GV sprint. It is fundamentally **user-centered** – the entire week builds toward understanding how real users respond to the idea (as GV says, you get *“clear data from a realistic prototype”* instead of guessing). It embodies the **“fail fast”** ethos of lean startup: rather than investing weeks or months only to learn a concept was flawed, the sprint forces an early reckoning. There’s also a strong emphasis on **team alignment and collaboration**. By locking a diverse team in a room together (figuratively speaking) and giving them a structured process, silos are broken down. The sprint uses **time-boxing and structure** to democratize input – everyone sketches, everyone votes – which surfaces ideas from all corners, not just the loudest voices. Jake Knapp highlights that a sprint can *“replace the old defaults of office work”* (like endless email chains or open-ended meetings) with a focused, **energizing sprint mindset**. The presence of a Decider in the room ensures that business strategy is woven into the design decisions and that when choices are made on Wednesday, they stick (no second-guessing after the sprint). Finally, the sprint reflects a *“bias toward action”* – it values making something tangible (a prototype) and getting real feedback over abstract debate. In summary, the GV design sprint is as much about *how* teams work (fast, focused, user-driven, cooperative) as it is about *what* they produce. This cultural aspect – a blend of **design thinking with startup agility** – is a key part of its philosophy.

## Origins of Design Thinking and the Double Diamond Model

Parallel to the rise of design sprints, the broader concept of **Design Thinking** was gaining traction in the 2000s as a human-centered approach to innovation. While “design thinking” as a term dates back to academic discussions (e.g. Peter Rowe 1987, and even earlier ideas by Herbert Simon in 1969), its popularization is often credited to **IDEO** and the **Stanford d.school** in the 2000s. In 2005, Stanford University founded the Hasso Plattner Institute of Design (the **d.school**), led by David Kelley (IDEO’s founder) and others, to teach design thinking to students and professionals. Around the same time, IDEO’s CEO **Tim Brown** published a pivotal 2008 Harvard Business Review article titled “Design Thinking,” where he defined design thinking as a *“human-centered approach to innovation that draws from the designer's toolkit to integrate the needs of people, the possibilities of technology, and the requirements for business success.”*. This philosophy underlined that design thinking is about balancing desirability (user needs), feasibility (technology) and viability (business) – a **user-centered but holistic** problem-solving mindset.

Amid this growing movement, the **UK Design Council** introduced a landmark visualization of the design thinking process: the **Double Diamond model**. The Double Diamond was developed in 2003–2004 by the Design Council’s Design & Innovation team under **Richard Eisermann**, who was then the Director of Design & Innovation. Eisermann’s team sought to articulate a clear, memorable diagram of the design process that could be widely understood by designers and non-designers alike. They reviewed numerous design and innovation projects and methods, looking for common patterns. The resulting model, launched publicly in 2004, is a simple yet powerful visual: **two diamonds** in sequence, each diamond representing a divergent-thinking phase followed by a convergent-thinking phase. The phases were named **Discover, Define, Develop, Deliver**. Essentially, the first diamond covers finding and framing the right problem, and the second diamond covers developing and delivering the right solution. The Double Diamond quickly became *“world-renowned”* as a design framework and has been taught globally as a foundation of design thinking methodology.

**Key Influences and Early Implementations:** The Double Diamond was not invented from thin air – the Design Council team acknowledged *“standing on the shoulders of giants.”* They drew from decades of prior research on design process models from the 1960s through 1990s. Pioneers like Herbert Simon, Bruce Archer, Nigel Cross, Bela Banathy, and others had all proposed models involving **divergent and convergent phases**, iterative loops, and user focus. In fact, the very diamond shape had appeared earlier: IDEO engineers in the late ’90s described product development with a diamond-shaped divergent-convergent “kite” model, and business consultant Gary Hamel (with whom Eisermann worked at Whirlpool) had used a *Double Diamond* concept in innovation workshops. The Design Council team synthesized these ideas, codified the terminology, and popularized it through their programs and publications. Early implementations of the Double Diamond included its use as a guide within the Design Council’s public-sector and social innovation projects in the UK, as well as its adoption in design education curricula. By visualizing the process as two diamonds, it gave stakeholders a common language: for example, UK government agencies and nonprofits working with designers could understand when the team was in a “discover” mode versus a “develop” mode, etc. Over the years, the Double Diamond framework has been widely adopted beyond the UK – from corporate innovation teams to global design consultancies – as a universal map of **design thinking in action**.

It’s important to note that the Double Diamond itself is a high-level model. In practice, many organizations and schools have their own spin on design thinking stages that align with it. For instance, Stanford’s d.school teaches **five stages: Empathize, Define, Ideate, Prototype, Test**, which correspond to the Diamond phases (Empathize/Discover, Define, Ideate/Develop, Prototype & Test/Deliver). IDEO often describes three broad phases: Inspiration, Ideation, Implementation. These are all variations on the same theme – diverging to understand the problem, converging to define it, then diverging to ideate solutions, and converging to implement a solution. The Double Diamond’s contribution was giving a **clear, memorable diagram** for this, and it reinforced the message that **divergence and convergence are both necessary** and distinct activities in design. This model underpins what we refer to here as the “Design Thinking sprint,” which is essentially running a design project (often within a short time frame, e.g. a week or two) through the stages of the Double Diamond.

## Structure and Phases of the Design Thinking (Double Diamond) Sprint

In a design thinking sprint mapped to the **Double Diamond**, the process is typically organized into **four main phases**: **Discover, Define, Develop, and Deliver**. Each phase has its own objective and type of activities, alternating between broad exploration and focused refinement. When executed in a time-compressed sprint format (say a one-week workshop or a two-week project), these phases still occur, though sometimes overlapping or iterating. Let’s break down each stage and its goals, decisions, and methods:

* **Discover (Divergent Phase 1 – “Problem Exploration”):** The first stage is about casting a wide net to **research and understand the problem space**. The team seeks to learn about the users, context, and root issues at hand, rather than jumping to conclusions. Activities in Discover often include **user research** (e.g. interviewing people affected by the problem, shadowing users in context, or surveying), as well as exploring secondary research or analogous inspirations. The mindset is one of **empathy and curiosity** – as d.school puts it, *“work to fully understand the experience of the user for whom you are designing.”* By the end of Discover, the team typically has a pile of insights: pain points, user needs, and observations about the current state. A key outcome (and decision) of this phase is identifying promising *insight areas* or *opportunity areas* to focus on. The **Double Diamond’s principle** here is understanding the real problem: *“Understand the issue rather than simply assume what it is. It involves speaking to and spending time with people who are affected by the issues.”*. In a sprint context, the Discover phase might be condensed into the first day or two, where teams do quick field research or review existing data and share findings.

* **Define (Convergent Phase 1 – “Problem Definition”):** In the Define stage, the team synthesizes the findings from Discover to **clearly articulate the design challenge**. This often means narrowing in on a specific user group and need to address. Teams might create **personas** or empathy maps to summarize user characteristics, and use tools like **affinity mapping** to cluster insights. A common outcome is a **Point of View (POV) statement** or a well-framed **problem statement**. For example, a POV might be: “`<User type>` needs a way to `<do something>` because `<insight>`.” The Define phase is where **divergent insights converge into a clear definition** of *“what problem are we solving?”*. According to the Design Council, *“The insight gathered from the discovery phase can help you to define the challenge in a different way.”* Often teams generate **How Might We** questions here – broad yet focused questions that springboard into idea generation (e.g. “How might we help busy parents ensure their kids eat healthy meals on the go?”). The key decision in Define is **choosing a focal problem statement or design brief**. As the Design Council describes, *“The result is to create a design brief which clearly defines the challenge based on these insights.”*. In a sprint, this might occur mid-week or by end of day 1: the team agrees on a specific problem to tackle (from the broad topic they started with). This stage is critical because it ensures the sprint is solving the *right* problem before moving forward.

&#x20;*Depiction of the Design Council’s Double Diamond design process: teams first diverge to discover insights and define the true problem, then diverge again to develop ideas and converge on a deliverable solution. Each “diamond” represents a phase of broad exploration followed by focused refinement.*

* **Develop (Divergent Phase 2 – “Solution Exploration”):** Once the problem is well defined, the second diamond begins with developing possible solutions. This is the **ideation and prototyping** stage. The team generates a wide range of ideas that could address the defined problem. Techniques mirror those of other creative processes: brainstorming sessions (often guided by rules to encourage wild ideas and defer judgment), sketching concepts, and perhaps co-design workshops with users or stakeholders. The goal is to **diverge in search of multiple solution concepts** – *“give different answers to the clearly defined problem, seeking inspiration from elsewhere and co-designing with a range of different people.”*. Here, the design thinking philosophy of *“fluency over accuracy”* applies; quantity breeds quality. After generating ideas, the team will usually select a few ideas to prototype. They might use dot voting or criteria grids to evaluate which ideas best meet the user needs and success criteria defined earlier. The Develop phase then transitions into making **prototypes** of selected ideas. Depending on context, prototypes might be anything from a storyboard or paper mock-up, to a role-playing scenario, to a clickable digital demo, or even a rough physical model. Importantly, prototypes in design thinking are meant to be **low-cost learning devices** – built quickly to explore the idea, not to be final solutions. In a one-week sprint format, the Develop phase could span a day or two: one day for ideation, one for prototyping the top idea(s). The key decision in this phase is which solution(s) to carry forward. Often a team will prototype more than one concept if time permits (especially in a slightly longer sprint), to compare approaches. But even if one concept is chosen, alternatives are usually documented or kept in reserve. By the end of Develop, the team has one or more prototype solutions ready to test.

* **Deliver (Convergent Phase 2 – “Solution Implementation/Test”):** The final phase is about **testing and refining solutions**, ultimately converging on an outcome that can be delivered to the real world. In the classic Double Diamond, Deliver includes small-scale testing or pilots, launching the solution, and then iterating based on feedback. In a sprint scenario, the Deliver phase often centers on **user testing** the prototypes that were built. Much like the GV sprint’s Friday, a design thinking sprint would involve getting the prototype in front of users or stakeholders and gathering feedback. Methods here include usability testing, feedback workshops, or experiments. For instance, if multiple prototypes were created, a team might test all to see which approach resonates best. The data from testing is then used to **make decisions on how to move forward** – which solution to refine or combine, and what an implementation roadmap might look like. In a one-week sprint, this testing might happen on the last day, with the team then presenting results and a recommended next step (e.g., “Prototype B clearly performed best with users, so we propose to proceed with that direction.”). In a broader project context, Deliver could extend to actual implementation and release. According to the Design Council, *“Delivery involves testing out different solutions at small scale, rejecting those that will not work and improving the ones that will.”*. Thus, a key decision at the end of Deliver is **selecting the single solution** to fully launch (and perhaps getting approval or resources to do so). In design thinking, this final convergence is not necessarily the end of iteration – it’s understood that even delivered solutions will continue to evolve with further user feedback and changing conditions. But it marks the conclusion of the sprint in delivering a validated direction.

Throughout these phases, the **Double Diamond sprint maintains an iterative, user-centered approach.** Teams often loop back as needed – for example, early testing insights might send the team back to redefine the problem or try a new idea (the diagram’s arrows indicate it’s not strictly linear). Also, various **tools and methods** support each phase: In **Discover**, methods like interviews, observations, user journey mapping, and stakeholder mapping are common. In **Define**, methods such as insight synthesis, persona creation, POV statements, and HMW questions help clarify the challenge. In **Develop**, ideation techniques (brainwriting, sketching, SCAMPER, etc.), as well as prototyping methods (paper prototyping, bodystorming, role-play scenarios) are used. In **Deliver**, user testing techniques, surveys, or A/B experiments might be employed. The underlying **philosophy** here is pure design thinking: start with empathy for the user, **converge to a sharp problem definition (solving the right problem)**, then ideate and prototype to **iterate toward the right solution**, keeping the user involved through testing. This framework assumes that by following these phases, teams can arrive at innovative solutions to even ill-defined (“wicked”) problems. It’s more **open-ended** than the prescriptive GV sprint – design thinking sprints can vary in length and form – but the Double Diamond provides a **conceptual map** that keeps teams mindful of when to diverge and when to converge.

## Underlying Philosophy of Design Thinking Sprints

The **Design Thinking** approach (as exemplified by the Double Diamond) rests on several key beliefs and principles. First and foremost is **human-centeredness**: the idea that understanding the people affected by a problem is paramount to innovating effectively. This is why empathy and user research are the starting point. Tim Brown’s oft-cited definition emphasizes this human-centered focus as well as the integration of technological and business considerations – design thinking seeks solutions that are desirable for users, feasible to implement, and viable in the market. Another core philosophy is embracing **divergent thinking** (exploring lots of options, thinking broadly) and **convergent thinking** (making choices and focusing) as equally important. The Double Diamond’s shape graphically underscores that teams need to **go wide before they go narrow**, both in understanding the problem and in creating solutions. This counters the common pitfall of jumping to solutions or sticking with the first idea. Instead, design thinking encourages teams to entertain many ideas and learn from them through rapid prototyping.

**Iterative experimentation** is another pillar: it’s understood that the design process is not linear. The phases can loop (e.g., new insights from testing might prompt more user research or a redefinition of the problem). The mantra *“fail early to succeed sooner”* fits here – prototypes are built to expose flaws and provoke feedback, so improvements can be made while the stakes are low. Design thinking also espouses **collaboration and cross-functional teamwork**. The best insights and ideas often come from mixing perspectives – hence, sprint teams typically include members from different disciplines (design, engineering, business, etc.) and often involve the users or customers as co-creators at points (through interviews, co-design sessions, etc.). This inclusive approach aligns the team around user needs and breaks down siloed thinking.

Crucially, design thinking is often described as a **mindset or philosophy** more than a strict method. Unlike the GV sprint (which is a specific recipe), design thinking can flex. It’s described as *“an overall philosophy for approaching problem-solving”*, whereas a design sprint is *“a method for creating a prototype with limited time and resources.”*. In practical terms, this means a design thinking sprint might adapt to the context – some problems might require a lengthy discover phase and a short develop phase; others vice versa. The assumptions behind design thinking are optimistic: it assumes *creative solutions are possible* for nearly any problem if we deeply understand human needs and think creatively; it assumes *everyone has the capacity to contribute creatively* (often citing the idea of building “creative confidence” in team members); and it assumes that *through iterative cycles* we can navigate uncertainty.

One could say the design thinking sprint’s philosophy is about **solving the right problem and solving the problem right**. The first diamond (Discover/Define) is about the former – make sure you’re addressing a real, significant need. The second diamond (Develop/Deliver) is about the latter – ensure the solution is effective and well-received. This stands in contrast to more linear or hypothesis-driven approaches by insisting on a period of **problem reframing** and on tangible user feedback as validation. The ultimate goal is often **innovation** – not just any solution, but a breakthrough that genuinely improves things for users. Thus, design thinking is often applied to broad, fuzzy challenges (e.g., improving healthcare experiences, making cities more livable, etc.) where the problem itself needs definition. In summary, the design thinking sprint, guided by the Double Diamond, is underpinned by user-centricity, creativity, iterative learning, and a balanced consideration of desirability, feasibility, and viability.

## Comparing the GV Design Sprint and the Design Thinking (Double Diamond) Sprint

Both the GV Design Sprint and the Design Thinking/Double Diamond sprint are iterative, human-centered approaches to problem solving, but they differ in **scope, speed, and specificity**. Understanding their commonalities and differences can help teams choose the right approach for a given project.

**Shared DNA:** At a high level, the two models share a lot of DNA because the design sprint was directly influenced by design thinking. As Jake Knapp himself noted, the sprint’s structure was *“based on a strategy developed by IDEO and Stanford’s d.school.”* In essence, the five-day sprint condenses the stages of empathy/research, definition, ideation, prototyping, and testing into one work week. Both approaches are **user-centered**, relying on user feedback to guide decisions. Both are **highly collaborative**, bringing cross-functional teams together. And both value **iteration** and **fast learning** – whether it’s through quick sketches in a sprint or multiple prototypes in design thinking, there’s a bias toward making ideas tangible and learning from doing. Notably, both also address the dual goal of achieving team alignment and solving problems creatively. By the end of either process, the team has a clearer shared understanding of the challenge and potential solution.

**Differences in Goals and Scope:** The key differences lie in **goals and applicability**. The **GV Design Sprint** was designed to answer *very specific questions* and validate concrete product ideas in a short time. It works best when you have a relatively defined problem or product concept and need to test a solution or a feature set rapidly. It’s essentially a **product design sprint** – originally honed for tech startups building apps, websites, or tangible products. As such, its outcome is typically a prototype of a *specific solution*. In contrast, **Design Thinking (Double Diamond)** can be applied to much broader or **open-ended problems**. It’s often described as a mindset or framework that can tackle “wicked problems” or systemic challenges beyond just a single product. Its goal can range from redefining a problem (you might spend a whole project just on the first diamond) to iteratively developing a new service or strategy. Design thinking doesn’t always yield a prototype in five days; it might yield a better understanding of the problem or a roadmap of opportunities if that’s what’s needed. **In short, design sprints are tactical and focused (solve *this* problem, build *this* thing quickly), whereas design thinking is strategic and expansive (ensure we’re solving the *right* problem and consider many possibilities).** One source summarizes: *“Design sprints are used to solve specific problems, whereas design thinking is applied for general ones. Design thinking is an overall philosophy… while design sprints are a method for creating a prototype with limited time and resources.”*.

**Process and Timeframe:** Another distinction is the **timeframe and rigidity of structure**. The GV sprint is a very fixed time-box – five days, with a pretty strict agenda for each day. It’s literally a “sprint” in the sense of a short, intense effort. This fixed recipe is one of its strengths – it’s easy to follow and replicate, and as some practitioners say, it’s *“design thinking with a stopwatch”* (every activity timed). Design Thinking via the Double Diamond is **more flexible**. The Double Diamond doesn’t dictate how long each phase should take – it could be one day each in a 4-day workshop, or it could be months each in a large innovation project. Thus, a design thinking “sprint” might not always be just five days; some companies run “design thinking sprints” of two weeks or more, especially if more in-depth research or multiple test iterations are included. The design sprint’s advantage is speed and efficiency – by the end of the week you *will have* a tested prototype, whereas a design thinking approach might encourage more exploration if needed. The flip side is that design sprints assume you can get enough insight in a week; if the problem is very broad or unknown, a GV sprint might be premature (you might first need a separate research phase).

**Roles and Team Composition:** In a GV sprint, roles like the **Decider** are explicit, and the presence of a facilitator is assumed (often the designer or design partner leading the sprint). There’s also usually a small, tight team. Design thinking efforts can involve larger, more fluid teams and sometimes multiple stakeholders throughout (e.g., you might engage end-users in co-design during Develop, or have executives partake in Define workshops). Design thinking also integrates more with *implementation teams* when going into Delivery for real; a GV sprint by itself stops at validation, after which a product team would still have to build the real product (often with the sprint team’s insights handed off).

**Documentation and Guidance:** GV provides checklists, a playbook (the Sprint book), and concrete exercises, making it very **practical and prescriptive**. Design thinking has lots of toolkits (IDEO’s methods, d.school bootcamp bootleg, etc.), but it requires more tailoring by the team. In other words, design thinking is *principle-driven*, whereas the GV sprint is *process-driven*. A novice team can run a GV sprint by following the steps; a novice team doing design thinking might need a skilled facilitator to choose the right methods for each phase and guide the ambiguity.

**Outcome and Metrics:** The success of a design sprint is often measured by *what you learn by Friday* – did we answer our sprint questions? Did the prototype validate or invalidate the hypothesis? It’s very much about reducing uncertainty quickly. Design thinking’s success might be measured in a broader sense – did we arrive at an innovative solution? Did we deeply understand the users? Are stakeholders aligned around the new insights? The design thinking approach might produce personas, journey maps, multiple prototypes, a refined problem statement, etc., as valuable artifacts even besides the final solution. Design sprints are more singularly focused on one concept (you pick one and go).

In terms of **applicability**, GV sprints shine in product/service design for startups, feature development, or any scenario where a team has a promising idea that needs quick validation (or when a project is stuck and needs a jump-start). Design thinking is applicable to almost anything – from redesigning an organizational process, to crafting policy, to social innovation – because it’s more of a *framework for creative problem solving*. That being said, many corporate innovation programs actually combine the two: they use design thinking principles and often execute them via time-bound sprints. In fact, some call the GV-style sprint a subset or a specific instance of design thinking in action. It’s fair to say **a design sprint is to design thinking as a hackathon is to programming** – a short, focused burst that uses the same principles, but doesn’t encompass the entirety of the discipline.

To summarize the comparison: Both models value *users, teamwork,* and *iteration*, but the GV Design Sprint is a **tightly scoped, recipe-driven method aimed at rapid prototyping and testing**, whereas the Design Thinking Double Diamond is a **broader methodology or mindset that can be scaled up or down**. The design sprint assumes you have a relatively defined problem/goal and pushes you to a solution in 5 days, whereas design thinking assumes you might need to *discover the problem* and *explore many solutions*, potentially requiring more divergence before convergence. A design sprint is like a **laser-focused short-term project**, while design thinking is the **overall approach** guiding innovation, of which a sprint can be one tool.

## Adapting These Models for Multiple Teams Under a Shared Theme

Both sprint models typically assume a single team working on a single problem. But in practice, organizations often face situations where **multiple teams sprint in parallel under a shared theme**. For example, a company might hold an innovation week where several teams each run a sprint on different aspects of a broader challenge (a bit like a hackathon with design sprints), or a large complex problem might be broken into sub-problems tackled by sub-teams simultaneously. Adapting the GV Sprint or Design Thinking process to this context requires some shifts in approach, but it can be highly effective if managed well.

**Parallel GV Design Sprints:** Jake Knapp and others have documented cases of running many design sprints at once. One famous example was at The New York Times “Maker Week,” where Knapp helped facilitate **13 design sprints running simultaneously** as part of an annual hackathon. In such a scenario, there is usually a common *theme or problem domain* (e.g. “improve the digital news experience”) and multiple teams each choose a specific angle or project within that theme. To manage this, an organization might use a **central facilitator or coordination team** – essentially an “MC” – to keep all teams in sync on time and activities. For instance, every team does their Monday mapping in the morning and perhaps shares their target briefly with the others to avoid overlap; then all teams move to Tuesday sketching, etc., with common check-in points. Logistically, it might look like a big workshop room with several tables (one per team), a lead facilitator on a microphone guiding the group through each exercise, and possibly floating facilitators or coaches to help individual teams as needed. This ensures consistency in pacing and that all teams hit the key milestones.

The benefit of parallel sprints is scale – you generate many more ideas and prototypes in the same time frame. For example, a startup accelerator might run a sprint week where each startup team works on their own product but they all share the schedule and certain resources (like guest experts for Lightning Demos, or a common pool of user testers). In some cases, teams might also share parts of **Monday’s Understand phase** if the theme is shared – e.g., a morning presentation about the domain or common research insights, before teams diverge into their specific focus. They might also jointly share **Friday’s test learnings** – for instance, each team presents their prototype and findings in a plenary session, allowing cross-pollination of lessons. However, one must guard against teams influencing each other’s concepts prematurely; it’s usually best that once problem areas are chosen, each team works independently to ensure a diversity of solutions.

**Coordinated Design Thinking Sprints:** In a design thinking context, multiple teams under one theme might be tackling a complex, multifaceted challenge. One approach is to divide the broad challenge into sub-challenges (by user segment, by sub-problem, by geographic market, etc.) and assign each to a team. All teams start with a common **brief and research kickoff** (ensuring everyone understands the overarching context and constraints), and then they diverge. During the **Discover** phase, teams might actually collaborate to some extent – for instance, splitting user research: one team interviews one set of users while another team interviews a different set, then they share insights collectively. This avoids duplicated effort and builds a richer picture. As they move into **Define**, a central facilitator might help ensure that each team’s defined problem statements are complementary (not all solving the exact same sliver, unless that’s intended).

During **Develop (ideation)**, teams work separately on their sub-problems, but cross-team communication can be valuable. Some programs schedule mid-sprint checkpoints where teams present their top ideas or storyboards to each other for feedback. This can spark new ideas or identify opportunities to align solutions. For example, if Team A is working on the onboarding experience and Team B on the core product interaction, their solutions might need to dovetail; sharing progress can help catch integration issues early. In the **Deliver/testing** phase, if the sub-solutions are related, one might even conduct a combined user testing session where a participant experiences multiple prototypes (though this can be logistically complex). More often, teams test separately but then meet to share results and see the bigger picture. A case study from Deutsche Telekom described a design sprint with **12 teams (70 participants) in one room, tackling sub-topics of one massive challenge**, which was treated as *“one mega-sprint”* with carefully orchestrated activities and moments for the sub-teams to reconnect. The organizers noted that this unified approach had far more *“power”* than if each team had sprinted in isolation – presumably because insights were shared and the final outcomes were more cohesive.

**Adjustments to the Models:** When running parallel sprints under a theme, several adjustments help: (1) **Common Alignment at Start:** Have a joint kickoff to align on the overarching mission, so all teams understand the “shared theme” deeply and why each sub-problem matters to it. Possibly have experts give talks or users share stories to all teams at once (this is akin to a collective Monday morning “Understand” session). (2) **Slightly Extended Planning:** Logistics like scheduling user tests might require more coordination – e.g., ensuring each team has a separate set of testers, or staggering the tests if using the same pool of users. The facilitation needs increase: often a **team of facilitators** is needed, one per team or at least roaming among teams, plus a lead to keep time and energy high. (3) **Sharing and Synthesis:** Build in sessions where teams share mid-point progress or final results. This could be informal daily stand-ups across teams or formal presentations at the end. The goal is cross-team learning, especially since they are all under one theme, their learnings might inform each other or even combine. (4) **Avoiding Groupthink:** While collaboration is good, one risk is all teams gravitating to similar ideas (especially if they overhear each other). To counter this, facilitators sometimes physically separate teams except during designated share-outs, maintaining a healthy independence of thought. Alternatively, giving each team a clearly distinct focus (so they’re not overlapping too much) helps – essentially dividing the problem well.

In terms of content, the **shared theme context** might mean that some phases yield outputs that benefit from integration. For instance, a **joint Discover** could produce a comprehensive research report that all teams use. A **joint Define** workshop might result in a set of problem statements that cover the theme’s breadth without gaps or redundancies. After the sprints, there might be an **integrative step** where the best ideas from different teams are considered together. If each team tackled a sub-problem, the sponsor of the overall theme would want to see how the solutions fit together. Sometimes, multiple parallel sprint teams will funnel into a **pitch competition** or decision meeting where leadership selects which solutions (or combination) to pursue further (common in hackathon-style sprint weeks or corporate innovation programs).

Both GV and design thinking frameworks are inherently flexible to scale this way – after all, they encourage divergence, and what is running multiple teams in parallel if not divergence at the process level? Organizations like Google have institutionalized this: Google’s Sprint Master Academy and others train facilitators to run simultaneous sprints, and startup accelerators often run cohort-wide sprint weeks. The **advantages** of parallel sprints under a theme are speed (tackling many facets at once) and a culture of widespread engagement (lots of people get to participate in innovation). The **challenges** include ensuring quality and consistency (not every team may have an experienced designer, so training and templates help) and then re-integrating the work into a coherent strategy.

One interesting twist is the idea of **sub-teams tackling parts of one complex challenge in one big room**. In that model, you might have periodic moments where team members actually rotate or merge to address intersections of the sub-problems, truly treating it as one big design exercise with multiple breakout groups. This is advanced facilitation but can be powerful for very complex, systemic issues. The key is **communication and synthesis**: the more parallel tracks, the more important it is to have checkpoints where knowledge is shared and aligned.

In conclusion, adapting these models for multiple parallel teams means amplifying the coordination without losing the independence of each sprint. The GV sprint’s tightly timed agenda can be a boon here – it acts like a drumbeat so that 10 teams can march in unison through the week. The design thinking model’s emphasis on understanding the holistic problem ensures that even if teams split up, they remain connected to the larger mission. When done well, parallel sprints under a shared theme can generate a portfolio of innovative concepts and foster a sense of **collective momentum** in tackling big challenges, all within the spirit of fast-paced, user-focused design.

## Conclusion

Both the Google Ventures Design Sprint and the Design Thinking Double Diamond sprint have revolutionized how teams approach problem-solving and innovation. The **GV Design Sprint** originated from the fast-moving world of tech startups, bringing a laser-focused, time-boxed discipline that transforms an idea into a tested prototype in just five days. Its structure – Understand, Sketch, Decide, Prototype, Test – and the accompanying tools enable teams to shortcut months of work, align stakeholders, and most importantly, learn from real users with minimal delay. The **Design Thinking/Double Diamond** model, rooted in decades of design methodology and popularized by institutions like IDEO, Stanford d.school, and the Design Council, provides a broad and flexible framework. It emphasizes deeply understanding the problem (Discover/Define) before ideating and iterating solutions (Develop/Deliver), ensuring that innovation is anchored in real human needs and creative exploration.

When comparing the two, it’s clear that a design sprint is essentially **design thinking in microcosm** – a concentrated dose aimed at a specific question – whereas design thinking is a more expansive philosophy that can guide projects of any scale. Each has its place: if a team has a well-scoped challenge and needs a tangible result by Friday, the GV sprint is ideal; if the challenge is fuzzy and complex, a more open-ended design thinking process (perhaps consisting of multiple sprints or cycles) may be warranted. Many organizations use them hand-in-hand: a design thinking mindset to choose the right problems, and design sprints to tackle them quickly and iteratively.

Historically, these models emerged to address a common need – the need to innovate faster and more effectively by keeping people (users, customers) at the heart of the process. They replaced or supplemented traditional linear design processes with something more **agile and experimental**. Figures like Jake Knapp and Tim Brown, and institutions like Google Ventures and the Design Council, have through trial and refinement given the world robust templates for innovation.

Finally, as we saw, these models are not just for single-team product design – they can scale to involve multiple teams working in parallel, attacking different facets of a grand challenge. In such scenarios, careful orchestration allows an entire organization to engage in a design sprint or design thinking exercise simultaneously, yielding a wealth of ideas and insights in a short time. This ability to **adapt and scale** speaks to the versatility of the underlying principles: clear communication, user focus, time constraint to drive focus, and a balance of divergent and convergent thinking.

In a world where speed and innovation are at a premium, the GV Design Sprint and the Double Diamond design thinking process offer complementary approaches. They remind us that with the right process, a team can accomplish in days what might otherwise take months – and that the best solutions come not from prolonged pondering but from a cycle of *understand, create, test, and learn*. Equipped with these models, teams across industries continue to solve big problems and test new ideas, one sprint at a time, whether in the span of a week or through an ongoing journey of design thinking.

**Sources:**

* Knapp, J., Zeratsky, J., & Kowitz, B. (2016). *Sprint: How to Solve Big Problems and Test New Ideas in Just Five Days*. (Google Ventures Design Sprint official methodology)
* Google Ventures. “The Design Sprint.” *GV.com*
* Rao, L. (2013). “Inside A Google Ventures Design Sprint.” *TechCrunch*, Oct 23, 2013
* Design Council UK. “Framework for Innovation: Design Council’s Double Diamond.” (2004)
* Design Council UK. “History of the Double Diamond.” (2023)
* Brown, T. (2008). “Design Thinking.” *Harvard Business Review*, June 2008
* Interaction Design Foundation. “What is Design Thinking?” (n.d.)
* Eleken UX Blog. “Design Thinking vs Design Sprint: What’s the Difference?” (n.d.)
* Sasaki, T. (2018). “Tracing the shapes of multiple Design Sprints — a proposed typology.” *Medium*, AQ blog.
* PixelTree. “What are the steps in a Design Sprint Process?” (Chris Freeman, 2023)
